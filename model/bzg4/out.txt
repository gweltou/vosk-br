running path.sh
running cmd.sh

===== VALIDATING DATA =====


utils/validate_data_dir.sh: file data/train/utt2spk is not sorted or has duplicates
utils/validate_data_dir.sh: file data/test/utt2spk is not sorted or has duplicates
utils/fix_data_dir.sh: file data/train/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/train/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 13612 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/fix_data_dir.sh: file data/test/utt2spk is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/spk2utt is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/text is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/segments is not in sorted order or not unique, sorting it
utils/fix_data_dir.sh: file data/test/wav.scp is not in sorted order or not unique, sorting it
fix_data_dir.sh: kept all 2053 utterances.
fix_data_dir.sh: old files are kept in data/test/.backup
utils/prepare_lang.sh data/local/dict_nosp <UNK> data/local/lang_tmp_nosp data/lang_nosp
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt
prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 38 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 35 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
utils/validate_lang.pl data/lang_nosp
Checking existence of separator file
separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_nosp/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_nosp/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt
--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt
--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt
--> data/lang_nosp/phones/silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt
--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK

Checking data/lang_nosp/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt
--> data/lang_nosp/phones/roots.{txt, int} are OK

Checking data/lang_nosp/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt
--> data/lang_nosp/phones/sets.{txt, int} are OK

Checking data/lang_nosp/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt
--> data/lang_nosp/phones/extra_questions.{txt, int} are OK

Checking data/lang_nosp/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt
--> data/lang_nosp/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_nosp/phones/optional_silence.txt
--> data/lang_nosp/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_nosp/phones/disambig.txt has "#0" and "#1"
--> data/lang_nosp/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_nosp/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 83 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 22 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_nosp/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_nosp/oov.txt
--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt
--> data/lang_nosp/oov.{txt, int} are OK

--> data/lang_nosp/L.fst is olabel sorted
--> data/lang_nosp/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang_nosp]
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

done

===== FEATURES EXTRACTION =====

steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/train exp/make_mfcc/train mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/train
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for train
steps/make_mfcc.sh --nj 3 --cmd run.pl --mem 2G data/test exp/make_mfcc/test mfcc
utils/validate_data_dir.sh: Successfully validated data-directory data/test
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test
steps/compute_cmvn_stats.sh data/train exp/make_mfcc/train mfcc
Succeeded creating CMVN stats for train
steps/compute_cmvn_stats.sh data/test exp/make_mfcc/test mfcc
Succeeded creating CMVN stats for test

===== LANGUAGE MODEL CREATION =====
==== MAKING lm.arpa ====

done

==== MAKING G.fst ====

data/local/tmp/lm.arpa

===== MONO TRAINING =====

steps/train_mono.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono
steps/train_mono.sh: Initializing monophone system.
steps/train_mono.sh: Compiling training graphs
steps/train_mono.sh: Aligning data equally (pass 0)
steps/train_mono.sh: Pass 1
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 2
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 3
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 4
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 5
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 6
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 7
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 8
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 9
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 10
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 11
steps/train_mono.sh: Pass 12
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 13
steps/train_mono.sh: Pass 14
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 15
steps/train_mono.sh: Pass 16
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 17
steps/train_mono.sh: Pass 18
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 19
steps/train_mono.sh: Pass 20
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 21
steps/train_mono.sh: Pass 22
steps/train_mono.sh: Pass 23
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 24
steps/train_mono.sh: Pass 25
steps/train_mono.sh: Pass 26
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 27
steps/train_mono.sh: Pass 28
steps/train_mono.sh: Pass 29
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 30
steps/train_mono.sh: Pass 31
steps/train_mono.sh: Pass 32
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 33
steps/train_mono.sh: Pass 34
steps/train_mono.sh: Pass 35
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 36
steps/train_mono.sh: Pass 37
steps/train_mono.sh: Pass 38
steps/train_mono.sh: Aligning data
steps/train_mono.sh: Pass 39
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono/log/analyze_alignments.log
945 warnings in exp/mono/log/acc.*.*.log
237 warnings in exp/mono/log/update.*.log
9523 warnings in exp/mono/log/align.*.*.log
exp/mono: nj=3 align prob=-98.93 over 13.44h [retry=0.3%, fail=0.0%] states=135 gauss=977
steps/train_mono.sh: Done training monophone system in exp/mono

===== MONO DECODING =====

WARNING: the --mono, --left-biphone and --quinphone options are now deprecated and ignored.
-0.0514473 -0.052248
[info]: LG not stochastic.
-0.0514473 -0.052248
[info]: CLG not stochastic.
0.000199342 -0.103394
HCLGa is not stochastic

===== MONO ALIGNMENT =====

steps/align_si.sh --boost-silence 1.25 --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/mono exp/mono_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/mono, putting alignments in exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/mono_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/mono_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== TRI1 (first triphone pass) TRAINING =====

steps/train_deltas.sh --boost-silence 1.25 --cmd run.pl --mem 2G 2000 10000 data/train data/lang_nosp exp/mono_ali_train exp/tri1
steps/train_deltas.sh: accumulating tree stats
steps/train_deltas.sh: getting questions for tree-building, via clustering
steps/train_deltas.sh: building the tree
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
** The warnings above about 'no stats' generally mean you have phones **
** (or groups of phones) in your phone set that had no corresponding data. **
** You should probably figure out whether something went wrong, **
** or whether your data just doesn't happen to have examples of those **
** phones. **
steps/train_deltas.sh: converting alignments from exp/mono_ali_train to use current tree
steps/train_deltas.sh: compiling graphs of transcripts
steps/train_deltas.sh: training pass 1
steps/train_deltas.sh: training pass 2
steps/train_deltas.sh: training pass 3
steps/train_deltas.sh: training pass 4
steps/train_deltas.sh: training pass 5
steps/train_deltas.sh: training pass 6
steps/train_deltas.sh: training pass 7
steps/train_deltas.sh: training pass 8
steps/train_deltas.sh: training pass 9
steps/train_deltas.sh: training pass 10
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 11
steps/train_deltas.sh: training pass 12
steps/train_deltas.sh: training pass 13
steps/train_deltas.sh: training pass 14
steps/train_deltas.sh: training pass 15
steps/train_deltas.sh: training pass 16
steps/train_deltas.sh: training pass 17
steps/train_deltas.sh: training pass 18
steps/train_deltas.sh: training pass 19
steps/train_deltas.sh: training pass 20
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 21
steps/train_deltas.sh: training pass 22
steps/train_deltas.sh: training pass 23
steps/train_deltas.sh: training pass 24
steps/train_deltas.sh: training pass 25
steps/train_deltas.sh: training pass 26
steps/train_deltas.sh: training pass 27
steps/train_deltas.sh: training pass 28
steps/train_deltas.sh: training pass 29
steps/train_deltas.sh: training pass 30
steps/train_deltas.sh: aligning data
steps/train_deltas.sh: training pass 31
steps/train_deltas.sh: training pass 32
steps/train_deltas.sh: training pass 33
steps/train_deltas.sh: training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log
127 warnings in exp/tri1/log/acc.*.*.log
219 warnings in exp/tri1/log/align.*.*.log
5 warnings in exp/tri1/log/init_model.log
1 warnings in exp/tri1/log/build_tree.log
34 warnings in exp/tri1/log/update.*.log
1 warnings in exp/tri1/log/questions.log
exp/tri1: nj=3 align prob=-97.06 over 13.44h [retry=0.5%, fail=0.0%] states=1584 gauss=10027 tree-impr=3.83
steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1

===== TRI1 (first triphone pass) DECODING =====

0 -0.052248
[info]: CLG not stochastic.
0.612077 -0.142401
HCLGa is not stochastic

===== TRI1 ALIGNMENT =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri1 exp/tri1_ali_train
steps/align_si.sh: feature type is delta
steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri1_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== train an LDA+MLLT system =====

steps/train_lda_mllt.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali_train exp/tri2b
steps/train_lda_mllt.sh: Accumulating LDA statistics.
steps/train_lda_mllt.sh: Accumulating tree stats
steps/train_lda_mllt.sh: Getting questions for tree clustering.
steps/train_lda_mllt.sh: Building the tree
steps/train_lda_mllt.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali_train to use current tree
steps/train_lda_mllt.sh: Compiling graphs of transcripts
Training pass 1
Training pass 2
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 3
Training pass 4
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 5
Training pass 6
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 7
Training pass 8
Training pass 9
Training pass 10
Aligning data
Training pass 11
Training pass 12
steps/train_lda_mllt.sh: Estimating MLLT
Training pass 13
Training pass 14
Training pass 15
Training pass 16
Training pass 17
Training pass 18
Training pass 19
Training pass 20
Aligning data
Training pass 21
Training pass 22
Training pass 23
Training pass 24
Training pass 25
Training pass 26
Training pass 27
Training pass 28
Training pass 29
Training pass 30
Aligning data
Training pass 31
Training pass 32
Training pass 33
Training pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log
161 warnings in exp/tri2b/log/acc.*.*.log
4 warnings in exp/tri2b/log/lda_acc.*.log
1 warnings in exp/tri2b/log/build_tree.log
242 warnings in exp/tri2b/log/align.*.*.log
1 warnings in exp/tri2b/log/questions.log
51 warnings in exp/tri2b/log/update.*.log
13 warnings in exp/tri2b/log/init_model.log
exp/tri2b: nj=3 align prob=-45.26 over 13.43h [retry=0.5%, fail=0.0%] states=2000 gauss=15025 tree-impr=4.13 lda-sum=15.47 mllt:impr,logdet=1.00,1.39
steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b

===== Align utts using the tri2b model =====

steps/align_si.sh --nj 3 --cmd run.pl --mem 2G --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali_train
steps/align_si.sh: feature type is lda
steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri2b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali_train/log/analyze_alignments.log
steps/align_si.sh: done aligning data.

===== Train tri3b, which is LDA+MLLT+SAT =====

steps/train_sat.sh --cmd run.pl --mem 2G 2500 15000 data/train data/lang_nosp exp/tri2b_ali_train exp/tri3b
steps/train_sat.sh: feature type is lda
steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali_train
steps/train_sat.sh: Accumulating tree stats
steps/train_sat.sh: Getting questions for tree clustering.
steps/train_sat.sh: Building the tree
steps/train_sat.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/train_sat.sh: Converting alignments from exp/tri2b_ali_train to use current tree
steps/train_sat.sh: Compiling graphs of transcripts
Pass 1
Pass 2
Estimating fMLLR transforms
Pass 3
Pass 4
Estimating fMLLR transforms
Pass 5
Pass 6
Estimating fMLLR transforms
Pass 7
Pass 8
Pass 9
Pass 10
Aligning data
Pass 11
Pass 12
Estimating fMLLR transforms
Pass 13
Pass 14
Pass 15
Pass 16
Pass 17
Pass 18
Pass 19
Pass 20
Aligning data
Pass 21
Pass 22
Pass 23
Pass 24
Pass 25
Pass 26
Pass 27
Pass 28
Pass 29
Pass 30
Aligning data
Pass 31
Pass 32
Pass 33
Pass 34
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang_nosp exp/tri3b
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log
32 warnings in exp/tri3b/log/fmllr.*.*.log
1 warnings in exp/tri3b/log/est_alimdl.log
3 warnings in exp/tri3b/log/init_model.log
1 warnings in exp/tri3b/log/questions.log
35 warnings in exp/tri3b/log/update.*.log
262 warnings in exp/tri3b/log/align.*.*.log
1 warnings in exp/tri3b/log/build_tree.log
220 warnings in exp/tri3b/log/acc.*.*.log
steps/train_sat.sh: Likelihood evolution:
-48.763 -48.5323 -48.1711 -47.7278 -46.5771 -46.1377 -45.8258 -45.4967 -45.2196 -44.6229 -44.3484 -44.3108 -44.0128 -43.8849 -43.7601 -43.6553 -43.563 -43.4729 -43.369 -43.1574 -43.0394 -42.9739 -42.921 -42.8706 -42.8154 -42.7569 -42.7033 -42.6547 -42.6081 -42.518 -42.4551 -42.4289 -42.4129 -42.4021 
exp/tri3b: nj=3 align prob=-45.69 over 13.43h [retry=0.4%, fail=0.1%] states=2016 gauss=15020 fmllr-impr=3.04 over 8.90h tree-impr=6.00
steps/train_sat.sh: done training SAT system in exp/tri3b

===== compute the pronunciation and silence probabilities =====

steps/get_prons.sh --cmd run.pl --mem 2G data/train data/lang_nosp exp/tri3b
steps/get_prons.sh: exp/tri3b/ali.1.gz exists, so starting from alignments.
steps/get_prons.sh: done writing prons to exp/tri3b/prons.*.gz, silence counts in 
steps/get_prons.sh: exp/tri3b/sil_counts_nowb.txt and pronunciation counts in 
steps/get_prons.sh: exp/tri3b/pron_counts.{int,txt}
steps/get_prons.sh: ... and also in exp/tri3b/pron_counts_nowb.txt
Checking data/local/dict_nosp/silence_phones.txt ...
--> reading data/local/dict_nosp/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/silence_phones.txt is OK

Checking data/local/dict_nosp/optional_silence.txt ...
--> reading data/local/dict_nosp/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/optional_silence.txt is OK

Checking data/local/dict_nosp/nonsilence_phones.txt ...
--> reading data/local/dict_nosp/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict_nosp/lexicon.txt
--> reading data/local/dict_nosp/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexicon.txt is OK

Checking data/local/dict_nosp/lexiconp.txt
--> reading data/local/dict_nosp/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict_nosp/lexiconp.txt is OK

Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt
--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match

Checking data/local/dict_nosp/extra_questions.txt ...
--> data/local/dict_nosp/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict_nosp]

utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.
utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/
utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

Some low-probability prons include: 
# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8
euh 0.0333334 EU H
reont 0.0454546 R A I N T
ivez 0.048951 I V E Z
beza√± 0.0714286 B EY OE
neuze 0.0781251 N EN N
petra 0.0825396 P E R A
gwin 0.090909 V I N
arc'hant 0.104478 A R G A N T
utils/prepare_lang.sh data/local/dict <UNK> data/local/lang_tmp data/lang
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

prepare_lang.sh: validating output directory
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 76 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 37 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
utils/validate_lang.pl data/lang
Checking existence of separator file
separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt
--> data/lang/phones/context_indep.{txt, int, csl} are OK

Checking data/lang/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt
--> data/lang/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang/phones/silence.txt
--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt
--> data/lang/phones/silence.{txt, int, csl} are OK

Checking data/lang/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang/phones/disambig.txt
--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt
--> data/lang/phones/disambig.{txt, int, csl} are OK

Checking data/lang/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/roots.txt
--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt
--> data/lang/phones/roots.{txt, int} are OK

Checking data/lang/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang/phones/sets.txt
--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt
--> data/lang/phones/sets.{txt, int} are OK

Checking data/lang/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt
--> data/lang/phones/extra_questions.{txt, int} are OK

Checking data/lang/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt
--> data/lang/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang/phones/optional_silence.txt
--> data/lang/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang/phones/disambig.txt has "#0" and "#1"
--> data/lang/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 73 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 20 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang/oov.txt
--> data/lang/oov.int corresponds to data/lang/oov.txt
--> data/lang/oov.{txt, int} are OK

--> data/lang/L.fst is olabel sorted
--> data/lang/L_disambig.fst is olabel sorted
--> SUCCESS [validating lang directory data/lang]
Checking data/local/dict/silence_phones.txt ...
--> reading data/local/dict/silence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/silence_phones.txt is OK

Checking data/local/dict/optional_silence.txt ...
--> reading data/local/dict/optional_silence.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/optional_silence.txt is OK

Checking data/local/dict/nonsilence_phones.txt ...
--> reading data/local/dict/nonsilence_phones.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/nonsilence_phones.txt is OK

Checking disjoint: silence_phones.txt, nonsilence_phones.txt
--> disjoint property is OK.

Checking data/local/dict/lexicon.txt
--> reading data/local/dict/lexicon.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexicon.txt is OK

Checking data/local/dict/lexiconp.txt
--> reading data/local/dict/lexiconp.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp.txt is OK

Checking data/local/dict/lexiconp_silprob.txt
--> reading data/local/dict/lexiconp_silprob.txt
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/local/dict/lexiconp_silprob.txt is OK

Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt
--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match

Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt
--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match

Checking data/local/dict/extra_questions.txt ...
--> data/local/dict/extra_questions.txt is empty (this is OK)
--> SUCCESS [validating dictionary directory data/local/dict]

******* format_lms **********
utils/validate_lang.pl data/lang_test_tgsmall
Checking existence of separator file
separator file data/lang_test_tgsmall/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgsmall/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgsmall/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.int corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.csl corresponds to data/lang_test_tgsmall/phones/context_indep.txt
--> data/lang_test_tgsmall/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.int corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.csl corresponds to data/lang_test_tgsmall/phones/nonsilence.txt
--> data/lang_test_tgsmall/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.int corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.csl corresponds to data/lang_test_tgsmall/phones/silence.txt
--> data/lang_test_tgsmall/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.int corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.csl corresponds to data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.int corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.csl corresponds to data/lang_test_tgsmall/phones/disambig.txt
--> data/lang_test_tgsmall/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgsmall/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.int corresponds to data/lang_test_tgsmall/phones/roots.txt
--> data/lang_test_tgsmall/phones/roots.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.int corresponds to data/lang_test_tgsmall/phones/sets.txt
--> data/lang_test_tgsmall/phones/sets.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.int corresponds to data/lang_test_tgsmall/phones/extra_questions.txt
--> data/lang_test_tgsmall/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgsmall/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.int corresponds to data/lang_test_tgsmall/phones/word_boundary.txt
--> data/lang_test_tgsmall/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgsmall/phones/optional_silence.txt
--> data/lang_test_tgsmall/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgsmall/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgsmall/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgsmall/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgsmall/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgsmall/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgsmall/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 77 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 99 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgsmall/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.int corresponds to data/lang_test_tgsmall/oov.txt
--> data/lang_test_tgsmall/oov.{txt, int} are OK

--> data/lang_test_tgsmall/L.fst is olabel sorted
--> data/lang_test_tgsmall/L_disambig.fst is olabel sorted
--> data/lang_test_tgsmall/G.fst is ilabel sorted
--> data/lang_test_tgsmall/G.fst has 71919 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgsmall/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgsmall]
utils/validate_lang.pl data/lang_test_tgmed
Checking existence of separator file
separator file data/lang_test_tgmed/subword_separator.txt is empty or does not exist, deal in word case.
Checking data/lang_test_tgmed/phones.txt ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/phones.txt is OK

Checking words.txt: #0 ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> data/lang_test_tgmed/words.txt is OK

Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...
--> silence.txt and nonsilence.txt are disjoint
--> silence.txt and disambig.txt are disjoint
--> disambig.txt and nonsilence.txt are disjoint
--> disjoint property is OK

Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...
--> found no unexplainable phones in phones.txt

Checking data/lang_test_tgmed/phones/context_indep.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.int corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.csl corresponds to data/lang_test_tgmed/phones/context_indep.txt
--> data/lang_test_tgmed/phones/context_indep.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 160 entry/entries in data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.int corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.csl corresponds to data/lang_test_tgmed/phones/nonsilence.txt
--> data/lang_test_tgmed/phones/nonsilence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 15 entry/entries in data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.int corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.csl corresponds to data/lang_test_tgmed/phones/silence.txt
--> data/lang_test_tgmed/phones/silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.int corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.csl corresponds to data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/disambig.{txt, int, csl} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 6 entry/entries in data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.int corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.csl corresponds to data/lang_test_tgmed/phones/disambig.txt
--> data/lang_test_tgmed/phones/disambig.{txt, int, csl} are OK

Checking data/lang_test_tgmed/phones/roots.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.int corresponds to data/lang_test_tgmed/phones/roots.txt
--> data/lang_test_tgmed/phones/roots.{txt, int} are OK

Checking data/lang_test_tgmed/phones/sets.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 43 entry/entries in data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.int corresponds to data/lang_test_tgmed/phones/sets.txt
--> data/lang_test_tgmed/phones/sets.{txt, int} are OK

Checking data/lang_test_tgmed/phones/extra_questions.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 9 entry/entries in data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.int corresponds to data/lang_test_tgmed/phones/extra_questions.txt
--> data/lang_test_tgmed/phones/extra_questions.{txt, int} are OK

Checking data/lang_test_tgmed/phones/word_boundary.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 175 entry/entries in data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.int corresponds to data/lang_test_tgmed/phones/word_boundary.txt
--> data/lang_test_tgmed/phones/word_boundary.{txt, int} are OK

Checking optional_silence.txt ...
--> reading data/lang_test_tgmed/phones/optional_silence.txt
--> data/lang_test_tgmed/phones/optional_silence.txt is OK

Checking disambiguation symbols: #0 and #1
--> data/lang_test_tgmed/phones/disambig.txt has "#0" and "#1"
--> data/lang_test_tgmed/phones/disambig.txt is OK

Checking topo ...

Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...
--> data/lang_test_tgmed/phones/word_boundary.txt doesn't include disambiguation symbols
--> data/lang_test_tgmed/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt
--> data/lang_test_tgmed/phones/word_boundary.txt is OK

Checking word-level disambiguation symbols...
--> data/lang_test_tgmed/phones/wdisambig.txt exists (newer prepare_lang.sh)
Checking word_boundary.int and disambig.int
--> generating a 6 word/subword sequence
--> resulting phone sequence from L.fst corresponds to the word sequence
--> L.fst is OK
--> generating a 95 word/subword sequence
--> resulting phone sequence from L_disambig.fst corresponds to the word sequence
--> L_disambig.fst is OK

Checking data/lang_test_tgmed/oov.{txt, int} ...
--> text seems to be UTF-8 or ASCII, checking whitespaces
--> text contains only allowed whitespaces
--> 1 entry/entries in data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.int corresponds to data/lang_test_tgmed/oov.txt
--> data/lang_test_tgmed/oov.{txt, int} are OK

--> data/lang_test_tgmed/L.fst is olabel sorted
--> data/lang_test_tgmed/L_disambig.fst is olabel sorted
--> data/lang_test_tgmed/G.fst is ilabel sorted
--> data/lang_test_tgmed/G.fst has 71919 states
--> utils/lang/check_g_properties.pl successfully validated data/lang_test_tgmed/G.fst
--> utils/lang/check_g_properties.pl succeeded.
--> SUCCESS [validating lang directory data/lang_test_tgmed]
******* build_const_arpa *****
****** align_fmllr ********
steps/align_fmllr.sh --nj 3 --cmd run.pl --mem 2G data/train data/lang exp/tri3b exp/tri3b_ali_train
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train/log/analyze_alignments.log
5 warnings in exp/tri3b_ali_train/log/fmllr.*.log
37 warnings in exp/tri3b_ali_train/log/align_pass1.*.log
61 warnings in exp/tri3b_ali_train/log/align_pass2.*.log

===== STAGE 9 =====
==== Test the tri3b system with the silprobs and pron-probs ====

-0.0571074 -0.0575889
[info]: LG not stochastic.
0 -0.0575889
[info]: CLG not stochastic.
0.642366 -0.182762
HCLGa is not stochastic
****** decode_fmllr.sh ******
steps/decode_fmllr.sh --nj 3 --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test
steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 3 --cmd run.pl --mem 4G --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_tgsmall data/test exp/tri3b/decode_tgsmall_test.si
decode.sh: feature type is lda
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test.si
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,31) and mean=11.6
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test.si/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test.si/wer_10
%WER 39.40 [ 4129 / 10479, 653 ins, 593 del, 2883 sub ]
%SER 64.98 [ 1334 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_11
%WER 38.12 [ 3995 / 10479, 580 ins, 626 del, 2789 sub ]
%SER 63.57 [ 1305 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_12
%WER 37.20 [ 3898 / 10479, 509 ins, 655 del, 2734 sub ]
%SER 62.93 [ 1292 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_13
%WER 36.51 [ 3826 / 10479, 455 ins, 688 del, 2683 sub ]
%SER 62.06 [ 1274 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_14
%WER 36.11 [ 3784 / 10479, 428 ins, 706 del, 2650 sub ]
%SER 61.86 [ 1270 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_15
%WER 35.86 [ 3758 / 10479, 408 ins, 736 del, 2614 sub ]
%SER 61.47 [ 1262 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_16
%WER 35.56 [ 3726 / 10479, 373 ins, 765 del, 2588 sub ]
%SER 61.32 [ 1259 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_17
%WER 35.19 [ 3688 / 10479, 329 ins, 791 del, 2568 sub ]
%SER 61.13 [ 1255 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_7
%WER 45.90 [ 4810 / 10479, 1033 ins, 485 del, 3292 sub ]
%SER 71.26 [ 1463 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_8
%WER 43.69 [ 4578 / 10479, 894 ins, 515 del, 3169 sub ]
%SER 69.26 [ 1422 / 2053 ]
exp/tri3b/decode_tgsmall_test.si/wer_9
%WER 41.49 [ 4348 / 10479, 766 ins, 562 del, 3020 sub ]
%SER 67.46 [ 1385 / 2053 ]
steps/decode_fmllr.sh: feature type is lda
steps/decode_fmllr.sh: getting first-pass fMLLR transforms.
steps/decode_fmllr.sh: doing main lattice generation phase
steps/decode_fmllr.sh: estimating fMLLR transforms a second time.
steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G exp/tri3b/graph_tgsmall exp/tri3b/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,2,23) and mean=8.7
steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
exp/tri3b/decode_tgsmall_test/wer_10
%WER 29.44 [ 3085 / 10479, 531 ins, 430 del, 2124 sub ]
%SER 55.97 [ 1149 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_11
%WER 28.35 [ 2971 / 10479, 464 ins, 443 del, 2064 sub ]
%SER 54.90 [ 1127 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_12
%WER 27.75 [ 2908 / 10479, 435 ins, 461 del, 2012 sub ]
%SER 54.16 [ 1112 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_13
%WER 27.05 [ 2835 / 10479, 404 ins, 472 del, 1959 sub ]
%SER 53.04 [ 1089 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_14
%WER 26.45 [ 2772 / 10479, 372 ins, 485 del, 1915 sub ]
%SER 52.17 [ 1071 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_15
%WER 26.12 [ 2737 / 10479, 341 ins, 500 del, 1896 sub ]
%SER 51.68 [ 1061 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_16
%WER 25.89 [ 2713 / 10479, 326 ins, 514 del, 1873 sub ]
%SER 51.39 [ 1055 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_17
%WER 25.89 [ 2713 / 10479, 311 ins, 532 del, 1870 sub ]
%SER 51.00 [ 1047 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_7
%WER 34.09 [ 3572 / 10479, 754 ins, 404 del, 2414 sub ]
%SER 61.47 [ 1262 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_8
%WER 32.25 [ 3380 / 10479, 678 ins, 420 del, 2282 sub ]
%SER 59.13 [ 1214 / 2053 ]
exp/tri3b/decode_tgsmall_test/wer_9
%WER 30.82 [ 3230 / 10479, 592 ins, 433 del, 2205 sub ]
%SER 57.77 [ 1186 / 2053 ]
****** lmrescore.sh ******
steps/lmrescore.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tgmed data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tgmed_test
exp/tri3b/decode_tgmed_test/wer_10
%WER 29.04 [ 3043 / 10479, 490 ins, 446 del, 2107 sub ]
%SER 55.28 [ 1135 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_11
%WER 27.87 [ 2920 / 10479, 431 ins, 461 del, 2028 sub ]
%SER 54.07 [ 1110 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_12
%WER 27.24 [ 2854 / 10479, 394 ins, 481 del, 1979 sub ]
%SER 53.14 [ 1091 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_13
%WER 26.73 [ 2801 / 10479, 364 ins, 499 del, 1938 sub ]
%SER 52.22 [ 1072 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_14
%WER 26.19 [ 2744 / 10479, 329 ins, 507 del, 1908 sub ]
%SER 51.34 [ 1054 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_15
%WER 25.91 [ 2715 / 10479, 309 ins, 524 del, 1882 sub ]
%SER 51.10 [ 1049 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_16
%WER 25.64 [ 2687 / 10479, 302 ins, 538 del, 1847 sub ]
%SER 50.66 [ 1040 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_17
%WER 25.67 [ 2690 / 10479, 295 ins, 553 del, 1842 sub ]
%SER 50.56 [ 1038 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_7
%WER 33.51 [ 3512 / 10479, 711 ins, 416 del, 2385 sub ]
%SER 60.74 [ 1247 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_8
%WER 31.83 [ 3335 / 10479, 640 ins, 430 del, 2265 sub ]
%SER 58.50 [ 1201 / 2053 ]
exp/tri3b/decode_tgmed_test/wer_9
%WER 30.41 [ 3187 / 10479, 556 ins, 452 del, 2179 sub ]
%SER 57.04 [ 1171 / 2053 ]
****** lmrescore_const_arpa.sh ******
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test exp/tri3b/decode_tgsmall_test exp/tri3b/decode_tglarge_test
exp/tri3b/decode_tglarge_test/wer_10
%WER 29.06 [ 3045 / 10479, 489 ins, 450 del, 2106 sub ]
%SER 55.28 [ 1135 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_11
%WER 27.87 [ 2921 / 10479, 430 ins, 463 del, 2028 sub ]
%SER 54.07 [ 1110 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_12
%WER 27.25 [ 2856 / 10479, 391 ins, 481 del, 1984 sub ]
%SER 53.14 [ 1091 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_13
%WER 26.72 [ 2800 / 10479, 361 ins, 501 del, 1938 sub ]
%SER 52.22 [ 1072 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_14
%WER 26.20 [ 2745 / 10479, 328 ins, 510 del, 1907 sub ]
%SER 51.34 [ 1054 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_15
%WER 25.92 [ 2716 / 10479, 309 ins, 526 del, 1881 sub ]
%SER 51.10 [ 1049 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_16
%WER 25.68 [ 2691 / 10479, 303 ins, 540 del, 1848 sub ]
%SER 50.66 [ 1040 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_17
%WER 25.68 [ 2691 / 10479, 295 ins, 556 del, 1840 sub ]
%SER 50.56 [ 1038 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_7
%WER 33.51 [ 3512 / 10479, 709 ins, 417 del, 2386 sub ]
%SER 60.79 [ 1248 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_8
%WER 31.80 [ 3332 / 10479, 638 ins, 432 del, 2262 sub ]
%SER 58.50 [ 1201 / 2053 ]
exp/tri3b/decode_tglarge_test/wer_9
%WER 30.39 [ 3185 / 10479, 554 ins, 455 del, 2176 sub ]
%SER 57.04 [ 1171 / 2053 ]

===== STAGE 10 =====
==== Train a chain model ====

local/chain/run_tdnn_1j_nogpu.sh 
local/nnet3/run_ivector_common.sh: preparing directory for low-resolution speed-perturbed data (for alignment)
fix_data_dir.sh: kept all 13612 utterances.
fix_data_dir.sh: old files are kept in data/train/.backup
utils/data/perturb_data_dir_speed_3way.sh: making sure the utt2dur and the reco2dur files are present
... in data/train, because obtaining it after speed-perturbing
... would be very slow, and you might need them.
utils/data/get_utt2dur.sh: data/train/utt2dur already exists with the expected length.  We won't recompute it.
utils/data/get_reco2dur.sh: obtaining durations from recordings
utils/data/get_reco2dur.sh: could not get recording lengths from sphere-file headers, using wav-to-duration
utils/data/get_reco2dur.sh: computed data/train/reco2dur
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed0.9
fix_data_dir.sh: kept all 13612 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed0.9/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed0.9
utils/data/perturb_data_dir_speed.sh: generated speed-perturbed version of data in data/train, in data/train_sp_speed1.1
fix_data_dir.sh: kept all 13612 utterances.
fix_data_dir.sh: old files are kept in data/train_sp_speed1.1/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_speed1.1
utils/data/combine_data.sh data/train_sp data/train data/train_sp_speed0.9 data/train_sp_speed1.1
utils/data/combine_data.sh: combined utt2uniq
utils/data/combine_data.sh: combined segments
utils/data/combine_data.sh: combined utt2spk
utils/data/combine_data.sh [info]: not combining utt2lang as it does not exist
utils/data/combine_data.sh: combined utt2dur
utils/data/combine_data.sh [info]: **not combining utt2num_frames as it does not exist everywhere**
utils/data/combine_data.sh: combined reco2dur
utils/data/combine_data.sh [info]: **not combining feats.scp as it does not exist everywhere**
utils/data/combine_data.sh: combined text
utils/data/combine_data.sh [info]: **not combining cmvn.scp as it does not exist everywhere**
utils/data/combine_data.sh [info]: not combining vad.scp as it does not exist
utils/data/combine_data.sh [info]: not combining reco2file_and_channel as it does not exist
utils/data/combine_data.sh: combined wav.scp
utils/data/combine_data.sh: combined spk2gender
fix_data_dir.sh: kept all 40836 utterances.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
utils/data/perturb_data_dir_speed_3way.sh: generated 3-way speed-perturbed version of data in data/train, in data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
local/nnet3/run_ivector_common.sh: making MFCC features for low-resolution speed-perturbed data
steps/make_mfcc.sh --cmd run.pl --mem 2G --nj 1 data/train_sp
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: It seems not all of the feature files were successfully procesed (40630 != 40836); consider using utils/fix_data_dir.sh data/train_sp
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp
steps/compute_cmvn_stats.sh data/train_sp
steps/compute_cmvn_stats.sh: warning: it seems not all of the speakers got cmvn stats (329 != 339);
Succeeded creating CMVN stats for train_sp
utils/fix_data_dir.sh: filtered /tmp/kaldi.EzW3/speakers from 339 to 329 lines based on filter data/train_sp/cmvn.scp.
utils/fix_data_dir.sh: filtered data/train_sp/spk2utt from 339 to 329 lines based on filter /tmp/kaldi.EzW3/speakers.
utils/fix_data_dir.sh: filtered data/train_sp/spk2gender from 339 to 329 lines based on filter /tmp/kaldi.EzW3/speakers.
fix_data_dir.sh: kept 40630 utterances out of 40760
utils/fix_data_dir.sh: filtered data/train_sp/wav.scp from 186 to 184 lines based on filter /tmp/kaldi.EzW3/recordings.
utils/fix_data_dir.sh: filtered data/train_sp/reco2dur from 186 to 184 lines based on filter /tmp/kaldi.EzW3/recordings.
fix_data_dir.sh: old files are kept in data/train_sp/.backup
local/nnet3/run_ivector_common.sh: aligning with the perturbed low-resolution data
steps/align_fmllr.sh --nj 1 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/tri3b_ali_train_sp
steps/align_fmllr.sh: feature type is lda
steps/align_fmllr.sh: compiling training graphs
steps/align_fmllr.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr.sh: computing fMLLR transforms
steps/align_fmllr.sh: doing final alignment.
steps/align_fmllr.sh: done aligning data.
steps/diagnostic/analyze_alignments.sh --cmd run.pl --mem 2G data/lang exp/tri3b_ali_train_sp
steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali_train_sp/log/analyze_alignments.log
132 warnings in exp/tri3b_ali_train_sp/log/align_pass1.*.log
13 warnings in exp/tri3b_ali_train_sp/log/fmllr.*.log
172 warnings in exp/tri3b_ali_train_sp/log/align_pass2.*.log
local/nnet3/run_ivector_common.sh: creating high-resolution MFCC features
utils/copy_data_dir.sh: copied data from data/train_sp to data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
utils/copy_data_dir.sh: copied data from data/test to data/test_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
utils/data/perturb_data_dir_volume.sh: data/train_sp_hires/feats.scp exists; moving it to data/train_sp_hires/.backup/ as it wouldn't be valid any more.
utils/data/perturb_data_dir_volume.sh: added volume perturbation to the data in data/train_sp_hires
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/train_sp_hires
utils/validate_data_dir.sh: Successfully validated data-directory data/train_sp_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: It seems not all of the feature files were successfully procesed (40527 != 40630); consider using utils/fix_data_dir.sh data/train_sp_hires
steps/make_mfcc.sh: Succeeded creating MFCC features for train_sp_hires
steps/compute_cmvn_stats.sh data/train_sp_hires
steps/compute_cmvn_stats.sh: warning: it seems not all of the speakers got cmvn stats (324 != 329);
Succeeded creating CMVN stats for train_sp_hires
utils/fix_data_dir.sh: filtered /tmp/kaldi.FCYW/speakers from 329 to 324 lines based on filter data/train_sp_hires/cmvn.scp.
utils/fix_data_dir.sh: filtered data/train_sp_hires/spk2utt from 329 to 324 lines based on filter /tmp/kaldi.FCYW/speakers.
utils/fix_data_dir.sh: filtered data/train_sp_hires/spk2gender from 329 to 324 lines based on filter /tmp/kaldi.FCYW/speakers.
fix_data_dir.sh: kept 40527 utterances out of 40592
utils/fix_data_dir.sh: filtered data/train_sp_hires/wav.scp from 184 to 183 lines based on filter /tmp/kaldi.FCYW/recordings.
utils/fix_data_dir.sh: filtered data/train_sp_hires/reco2dur from 184 to 183 lines based on filter /tmp/kaldi.FCYW/recordings.
fix_data_dir.sh: old files are kept in data/train_sp_hires/.backup
steps/make_mfcc.sh --nj 1 --mfcc-config conf/mfcc_hires.conf --cmd run.pl --mem 2G data/test_hires
steps/make_mfcc.sh: moving data/test_hires/feats.scp to data/test_hires/.backup
utils/validate_data_dir.sh: Successfully validated data-directory data/test_hires
steps/make_mfcc.sh [info]: segments file exists: using that.
steps/make_mfcc.sh: Succeeded creating MFCC features for test_hires
steps/compute_cmvn_stats.sh data/test_hires
Succeeded creating CMVN stats for test_hires
fix_data_dir.sh: kept all 2053 utterances.
fix_data_dir.sh: old files are kept in data/test_hires/.backup
local/nnet3/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 40527 to 10131
local/nnet3/run_ivector_common.sh: computing a PCA transform from the hires data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --mem 2G --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/nnet3/diag_ubm/train_sp_hires_subset exp/nnet3/pca_transform
Done estimating PCA transform in exp/nnet3/pca_transform
local/nnet3/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --mem 2G --nj 1 --num-frames 700000 --num-threads 8 exp/nnet3/diag_ubm/train_sp_hires_subset 512 exp/nnet3/pca_transform exp/nnet3/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/nnet3/diag_ubm already exists. Backing up diagonal UBM in exp/nnet3/diag_ubm/backup.v5A
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 1 machines, parallelized with 'run.pl --mem 2G'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/nnet3/run_ivector_common.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --mem 2G --nj 1 --num-threads 4 --num-processes 2 --online-cmvn-iextractor false data/train_sp_hires exp/nnet3/diag_ubm exp/nnet3/extractor
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_sp_hires to exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2, number of speakers changed from 324 to 20352
utils/validate_data_dir.sh: Successfully validated data-directory exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 exp/nnet3/ivectors_train_sp_hires/train_sp_hires_max2 exp/nnet3/extractor exp/nnet3/ivectors_train_sp_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_train_sp_hires using the extractor in exp/nnet3/extractor.
steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --mem 2G --nj 1 data/test_hires exp/nnet3/extractor exp/nnet3/ivectors_test_hires
steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors
steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs
steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3/ivectors_test_hires using the extractor in exp/nnet3/extractor.
local/chain/run_tdnn_1j_nogpu.sh: creating lang directory data/lang_chain with chain-type topology

====== STAGE 11 ======
steps/align_fmllr_lats.sh --nj 2 --cmd run.pl --mem 2G data/train_sp data/lang exp/tri3b exp/chain/tri3b_train_sp_lats
steps/align_fmllr_lats.sh: feature type is lda
steps/align_fmllr_lats.sh: compiling training graphs
steps/align_fmllr_lats.sh: aligning data in data/train_sp using exp/tri3b/final.alimdl and speaker-independent features.
steps/align_fmllr_lats.sh: computing fMLLR transforms
steps/align_fmllr_lats.sh: generating lattices containing alternate pronunciations.
steps/align_fmllr_lats.sh: done generating lattices from training transcripts.
12 warnings in exp/chain/tri3b_train_sp_lats/log/generate_lattices.*.log
13 warnings in exp/chain/tri3b_train_sp_lats/log/fmllr.*.log
134 warnings in exp/chain/tri3b_train_sp_lats/log/align_pass1.*.log

====== STAGE 12 ======
steps/nnet3/chain/build_tree.sh --frame-subsampling-factor 3 --context-opts --context-width=2 --central-position=1 --cmd run.pl --mem 2G 3500 data/train_sp data/lang_chain exp/tri3b_ali_train_sp exp/chain/tree_sp
steps/nnet3/chain/build_tree.sh: feature type is lda
steps/nnet3/chain/build_tree.sh: Using transforms from exp/tri3b_ali_train_sp
steps/nnet3/chain/build_tree.sh: Initializing monophone model (for alignment conversion, in case topology changed)
steps/nnet3/chain/build_tree.sh: Accumulating tree stats
steps/nnet3/chain/build_tree.sh: Getting questions for tree clustering.
steps/nnet3/chain/build_tree.sh: Building the tree
steps/nnet3/chain/build_tree.sh: Initializing the model
WARNING (gmm-init-model[5.5.1009~1-e4940]:InitAmGmm():gmm-init-model.cc:55) Tree has pdf-id 1 with no stats; corresponding phone list: 6 7 8 9 10 
This is a bad warning.
steps/nnet3/chain/build_tree.sh: Converting alignments from exp/tri3b_ali_train_sp to use current tree
steps/nnet3/chain/build_tree.sh: Done building tree

====== STAGE 13 ======
local/chain/run_tdnn_1j_nogpu.sh: creating neural net configs using the xconfig parser

====== STAGE 14 ======
steps/nnet3/chain/get_egs.sh --frames-overlap-per-eg 0 --cmd run.pl --mem 4G --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/nnet3/ivectors_train_sp_hires --left-context 30 --right-context 30 --left-context-initial -1 --right-context-final -1 --left-tolerance 5 --right-tolerance 5 --frame-subsampling-factor 3 --alignment-subsampling-factor 3 --stage 0 --frames-per-iter 3000000 --frames-per-eg 140,100,160 --srand 0 data/train_sp_hires exp/chain/tdnn1j_sp exp/chain/tri3b_train_sp_lats exp/chain/tdnn1j_sp/egs
steps/nnet3/chain/get_egs.sh: File data/train_sp_hires/utt2uniq exists, so ensuring the hold-out set includes all perturbed versions of the same source utterance.
steps/nnet3/chain/get_egs.sh: Holding out 300 utterances in validation set and 300 in training diagnostic set, out of total 40527.
steps/nnet3/chain/get_egs.sh: creating egs.  To ensure they are not deleted later you can do:  touch exp/chain/tdnn1j_sp/egs/.nodelete
steps/nnet3/chain/get_egs.sh: feature type is raw, with 'apply-cmvn'
steps/nnet3/chain/get_egs.sh: working out number of frames of training data
steps/nnet3/chain/get_egs.sh: working out feature dim
steps/nnet3/chain/get_egs.sh: creating 5 archives, each with 18248 egs, with
steps/nnet3/chain/get_egs.sh:   140,100,160 labels per example, and (left,right) context = (30,30)
steps/nnet3/chain/get_egs.sh: Getting validation and training subset examples in background.
steps/nnet3/chain/get_egs.sh: Generating training examples on disk
steps/nnet3/chain/get_egs.sh: Getting subsets of validation examples for diagnostics and combination.
steps/nnet3/chain/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/chain/get_egs.sh: Removing temporary archives, alignments and lattices
steps/nnet3/chain/get_egs.sh: Finished preparing training examples
steps/nnet2/remove_egs.sh: Finished deleting examples in exp/chain/tdnn1j_sp/egs
exp/chain/tdnn1j_sp: num-iters=150 nj=2..2 num-params=5.2M dim=40+100->2288 combine=-0.111->-0.104 (over 3) xent:train/valid[99,149]=(-2.12,-2.01/-2.27,-2.15) logprob:train/valid[99,149]=(-0.117,-0.102/-0.131,-0.112)
steps/nnet3/chain/train.py --stage=-10 --cmd=run.pl --mem 4G --feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires --feat.cmvn-opts=--norm-means=false --norm-vars=false --chain.xent-regularize 0.1 --chain.leaky-hmm-coefficient=0.1 --chain.l2-regularize=0.0 --chain.apply-deriv-weights=false --chain.lm-opts=--num-extra-lm-states=2000 --trainer.add-option=--optimization.memory-compression-level=2 --trainer.srand=0 --trainer.max-param-change=2.0 --trainer.num-epochs=20 --trainer.frames-per-iter=3000000 --trainer.optimization.num-jobs-initial=2 --trainer.optimization.num-jobs-final=2 --trainer.optimization.initial-effective-lrate=0.002 --trainer.optimization.final-effective-lrate=0.0002 --trainer.num-chunk-per-minibatch=128,64 --egs.chunk-width=140,100,160 --egs.dir= --egs.opts=--frames-overlap-per-eg 0 --cleanup.remove-egs=true --use-gpu=false --reporting.email= --feat-dir=data/train_sp_hires --tree-dir=exp/chain/tree_sp --lat-dir=exp/chain/tri3b_train_sp_lats --dir=exp/chain/tdnn1j_sp
['steps/nnet3/chain/train.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.online-ivector-dir=exp/nnet3/ivectors_train_sp_hires', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--chain.xent-regularize', '0.1', '--chain.leaky-hmm-coefficient=0.1', '--chain.l2-regularize=0.0', '--chain.apply-deriv-weights=false', '--chain.lm-opts=--num-extra-lm-states=2000', '--trainer.add-option=--optimization.memory-compression-level=2', '--trainer.srand=0', '--trainer.max-param-change=2.0', '--trainer.num-epochs=20', '--trainer.frames-per-iter=3000000', '--trainer.optimization.num-jobs-initial=2', '--trainer.optimization.num-jobs-final=2', '--trainer.optimization.initial-effective-lrate=0.002', '--trainer.optimization.final-effective-lrate=0.0002', '--trainer.num-chunk-per-minibatch=128,64', '--egs.chunk-width=140,100,160', '--egs.dir=', '--egs.opts=--frames-overlap-per-eg 0', '--cleanup.remove-egs=true', '--use-gpu=false', '--reporting.email=', '--feat-dir=data/train_sp_hires', '--tree-dir=exp/chain/tree_sp', '--lat-dir=exp/chain/tri3b_train_sp_lats', '--dir=exp/chain/tdnn1j_sp']

====== STAGE 15 ======
-0.0571074 -0.0575889
[info]: CLG not stochastic.
0.576057 -0.223661
HCLGa is not stochastic
0.496131 -0.140582
[info]: final HCLG is not stochastic.

====== STAGE 16 ======
steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --frames-per-chunk 140 --nj 102 --cmd run.pl --mem 4G --num-threads 4 --online-ivector-dir exp/nnet3/ivectors_test_hires exp/chain/tree_sp/graph_tgsmall data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final exp/chain/tree_sp/graph_tgsmall exp/chain/tdnn1j_sp/decode_tgsmall_test
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,94) and mean=40.5
steps/diagnostic/analyze_lats.sh: see stats in exp/chain/tdnn1j_sp/decode_tgsmall_test/log/analyze_lattice_depth_stats.log
score best paths
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_10
%WER 15.42 [ 1616 / 10479, 154 ins, 309 del, 1153 sub ]
%SER 37.60 [ 772 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_11
%WER 15.46 [ 1620 / 10479, 145 ins, 320 del, 1155 sub ]
%SER 37.70 [ 774 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_12
%WER 15.68 [ 1643 / 10479, 137 ins, 336 del, 1170 sub ]
%SER 38.29 [ 786 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_13
%WER 15.74 [ 1649 / 10479, 134 ins, 352 del, 1163 sub ]
%SER 38.63 [ 793 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_14
%WER 15.82 [ 1658 / 10479, 121 ins, 371 del, 1166 sub ]
%SER 39.16 [ 804 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_15
%WER 15.79 [ 1655 / 10479, 112 ins, 381 del, 1162 sub ]
%SER 39.31 [ 807 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_16
%WER 15.98 [ 1675 / 10479, 105 ins, 391 del, 1179 sub ]
%SER 39.60 [ 813 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_17
%WER 16.47 [ 1726 / 10479, 106 ins, 415 del, 1205 sub ]
%SER 40.23 [ 826 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_7
%WER 18.23 [ 1910 / 10479, 231 ins, 298 del, 1381 sub ]
%SER 41.74 [ 857 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_8
%WER 16.90 [ 1771 / 10479, 195 ins, 302 del, 1274 sub ]
%SER 40.09 [ 823 / 2053 ]
exp/chain/tdnn1j_sp/decode_tgsmall_test/wer_9
%WER 15.96 [ 1672 / 10479, 169 ins, 306 del, 1197 sub ]
%SER 38.68 [ 794 / 2053 ]
score confidence and timing with sclite
Decoding done.
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp/decode_tgsmall_test exp/chain/tdnn1j_sp/decode_tglarge_test
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_10
%WER 15.53 [ 1627 / 10479, 153 ins, 322 del, 1152 sub ]
%SER 38.04 [ 781 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_11
%WER 15.49 [ 1623 / 10479, 144 ins, 332 del, 1147 sub ]
%SER 37.85 [ 777 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_12
%WER 15.51 [ 1625 / 10479, 133 ins, 339 del, 1153 sub ]
%SER 38.14 [ 783 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_13
%WER 15.65 [ 1640 / 10479, 127 ins, 357 del, 1156 sub ]
%SER 38.43 [ 789 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_14
%WER 15.68 [ 1643 / 10479, 118 ins, 376 del, 1149 sub ]
%SER 38.97 [ 800 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_15
%WER 15.69 [ 1644 / 10479, 109 ins, 377 del, 1158 sub ]
%SER 39.06 [ 802 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_16
%WER 15.97 [ 1673 / 10479, 102 ins, 399 del, 1172 sub ]
%SER 39.45 [ 810 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_17
%WER 16.38 [ 1716 / 10479, 101 ins, 412 del, 1203 sub ]
%SER 40.19 [ 825 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_7
%WER 17.93 [ 1879 / 10479, 220 ins, 315 del, 1344 sub ]
%SER 41.65 [ 855 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_8
%WER 16.70 [ 1750 / 10479, 188 ins, 315 del, 1247 sub ]
%SER 39.94 [ 820 / 2053 ]
exp/chain/tdnn1j_sp/decode_tglarge_test/wer_9
%WER 15.88 [ 1664 / 10479, 161 ins, 325 del, 1178 sub ]
%SER 38.82 [ 797 / 2053 ]

====== STAGE 17 ======
steps/online/nnet3/prepare_online_decoding.sh --mfcc-config conf/mfcc_hires.conf data/lang_chain exp/nnet3/extractor exp/chain/tdnn1j_sp exp/chain/tdnn1j_sp_online
steps/online/nnet3/prepare_online_decoding.sh: preparing configuration files in /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf
steps/online/nnet3/prepare_online_decoding.sh: created config file /home/gweltaz/STT/kaldi/egs/bzg/exp/chain/tdnn1j_sp_online/conf/online.conf
steps/online/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 102 --cmd run.pl --mem 4G exp/chain/tree_sp/graph_tgsmall data/test exp/chain/tdnn1j_sp_online/decode_tgsmall_test
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_10
%WER 15.48 [ 1622 / 10479, 156 ins, 309 del, 1157 sub ]
%SER 37.90 [ 778 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_11
%WER 15.59 [ 1634 / 10479, 150 ins, 321 del, 1163 sub ]
%SER 37.90 [ 778 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_12
%WER 15.73 [ 1648 / 10479, 142 ins, 341 del, 1165 sub ]
%SER 38.33 [ 787 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_13
%WER 15.84 [ 1660 / 10479, 137 ins, 354 del, 1169 sub ]
%SER 38.77 [ 796 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_14
%WER 15.93 [ 1669 / 10479, 127 ins, 363 del, 1179 sub ]
%SER 39.26 [ 806 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_15
%WER 15.81 [ 1657 / 10479, 118 ins, 370 del, 1169 sub ]
%SER 39.31 [ 807 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_16
%WER 15.99 [ 1676 / 10479, 119 ins, 378 del, 1179 sub ]
%SER 39.80 [ 817 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_17
%WER 16.31 [ 1709 / 10479, 117 ins, 394 del, 1198 sub ]
%SER 40.28 [ 827 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_7
%WER 18.21 [ 1908 / 10479, 224 ins, 298 del, 1386 sub ]
%SER 41.89 [ 860 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_8
%WER 16.98 [ 1779 / 10479, 199 ins, 299 del, 1281 sub ]
%SER 40.28 [ 827 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tgsmall_test/wer_9
%WER 15.95 [ 1671 / 10479, 171 ins, 302 del, 1198 sub ]
%SER 38.43 [ 789 / 2053 ]
steps/lmrescore_const_arpa.sh --cmd run.pl --mem 4G data/lang_test_tgsmall data/lang_test_tglarge data/test_hires exp/chain/tdnn1j_sp_online/decode_tgsmall_test exp/chain/tdnn1j_sp_online/decode_tglarge_test
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_10
%WER 15.56 [ 1631 / 10479, 153 ins, 322 del, 1156 sub ]
%SER 38.19 [ 784 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_11
%WER 15.59 [ 1634 / 10479, 145 ins, 329 del, 1160 sub ]
%SER 38.09 [ 782 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_12
%WER 15.57 [ 1632 / 10479, 132 ins, 344 del, 1156 sub ]
%SER 38.19 [ 784 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_13
%WER 15.62 [ 1637 / 10479, 126 ins, 352 del, 1159 sub ]
%SER 38.33 [ 787 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_14
%WER 15.67 [ 1642 / 10479, 119 ins, 365 del, 1158 sub ]
%SER 38.87 [ 798 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_15
%WER 15.68 [ 1643 / 10479, 111 ins, 377 del, 1155 sub ]
%SER 39.02 [ 801 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_16
%WER 15.90 [ 1666 / 10479, 112 ins, 385 del, 1169 sub ]
%SER 39.65 [ 814 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_17
%WER 16.25 [ 1703 / 10479, 109 ins, 402 del, 1192 sub ]
%SER 40.28 [ 827 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_7
%WER 17.93 [ 1879 / 10479, 214 ins, 314 del, 1351 sub ]
%SER 41.31 [ 848 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_8
%WER 16.65 [ 1745 / 10479, 187 ins, 307 del, 1251 sub ]
%SER 40.09 [ 823 / 2053 ]
exp/chain/tdnn1j_sp_online/decode_tglarge_test/wer_9
%WER 15.83 [ 1659 / 10479, 162 ins, 321 del, 1176 sub ]
%SER 38.68 [ 794 / 2053 ]

===== run.sh script is finished =====

